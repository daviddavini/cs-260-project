{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.7 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1ee38ef4a5a9feb55287fd749643f13d043cb0a7addaab2a9c224cbe137c0062"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 0. Overview of this Notebook\n",
    "\n",
    "In this notebook, we train various models on the ogbn-arxiv dataset for node prediction. We start with GCN and Label Propagation, and work our way up to the GCN-LPA model. We highlight connections between the mathematical formulation of the algorithms and our PyTorch implementation.\n",
    "\n",
    "Much of the code is borrowed and reworked from code on the OGB leaderboard, including the OGB author's example code for GCN, as well as Horace He's Label Propagation code."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "import torch_sparse\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Replace this with argsparse code that is compatible with Jupyter Notebook\n",
    "\n",
    "class args:\n",
    "    hidden_channels = 256\n",
    "    num_layers = 3\n",
    "    dropout = 0.5"
   ]
  },
  {
   "source": [
    "# 1. Setup PyTorch and Load the Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setup PyTorch\n",
    "device = torch.device('cpu')\n",
    "\n",
    "## Load the dataset\n",
    "dataset = PygNodePropPredDataset(name='ogbn-arxiv', transform=T.ToSparseTensor())\n",
    "data = dataset[0]\n",
    "# TODO: What in the world does this line do? The OGB authors include it in their example code\n",
    "data.adj_t = data.adj_t.to_symmetric()\n",
    "data = data.to(device)\n",
    "\n",
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]"
   ]
  },
  {
   "source": [
    "## Connection to Mathematical Notation\n",
    "\n",
    "For the sake of understanding, here's a connection between mathematical notation and our code's dataset variables.\n",
    "\n",
    "The number of nodes $n \\in \\mathbb{N}$ is\n",
    "$$ n = \\text{data.num_nodes} $$\n",
    "\n",
    "The number of features for each node $F \\in \\mathbb{N}$ is\n",
    "$$ F = \\text{data.num_features} $$\n",
    "\n",
    "The number of possible labels $c \\in \\mathbb{N}$ is\n",
    "$$ c = \\text{dataset.num_classes} $$\n",
    "\n",
    "The number of labeled nodes $m \\in \\mathbb{N}$, $m < n$ is\n",
    "$$ m = \\text{train_idx.shape[0]} $$\n",
    "\n",
    "The feature matrix $X \\in \\mathbb{R}^{n \\times F}$ is the torch.Tensor object\n",
    "$$ X = \\text{data.x} $$\n",
    "\n",
    "The label vector $Y \\in \\mathbb{R}^n$, $Y_i \\in [0,c]$ is the torch.Tensor object\n",
    "$$ Y = \\text{data.y} $$\n",
    "\n",
    "The adjacency matrix $A \\in \\mathbb{R}^{n \\times n}$ is the torch_sparse.SparseTensor object\n",
    "$$ A = \\text{data.adj_t} $$\n",
    "\n",
    "I don't understand exactly what the code sets data.adj_t to yet... its possible that A is a \"modified\" adjacency matrix\n",
    "\n",
    "## Helpful Reference Code\n",
    "\n",
    "Below is some helpful reference code. These variables go unused (instead we use the data variable, to keep in parallel with the OGB example code). \n",
    "They are just here to further understand connections to the mathematical notation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Conversion to mathematical notation\n",
    "n = X.shape[0]\n",
    "f = X.shape[1]\n",
    "c = torch.unique(Y).numel()\n",
    "m = train_idx.shape[0]\n",
    "X = data.x\n",
    "Y = data.y\n",
    "A = data.adj_t\n",
    "\n",
    "## Helpful tests for reference\n",
    "assert type(X) == torch.Tensor \n",
    "assert type(Y) == torch.Tensor\n",
    "assert type(A) == torch_sparse.SparseTensor\n",
    "assert type(n) == int \n",
    "assert type(f) == int\n",
    "assert type(c) == int \n",
    "assert type(m) == int\n",
    "assert X.shape == torch.Size([n, f])\n",
    "assert Y.shape == torch.Size([n, 1])\n",
    "assert A.sizes() == [n, n] # NOTE: SparseTensor doesn't have a shape attribute!"
   ]
  },
  {
   "source": [
    "# 2. GCN (Graph Convolutional Network)\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers, \n",
    "                dropout):\n",
    "        super(GCN, self).__init__()\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        self.convs.append(GCNConv(in_channels, hidden_channels, cached=True))\n",
    "        self.bns = torch.nn.ModuleList()\n",
    "        self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(\n",
    "                GCNConv(hidden_channels, hidden_channels, cached=True))\n",
    "            self.bns.append(torch.nn.BatchNorm1d(hidden_channels))\n",
    "        self.convs.append(GCNConv(hidden_channels, out_channels, cached=True))\n",
    "\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for conv in self.convs:\n",
    "            conv.reset_parameters()\n",
    "        for bn in self.bns:\n",
    "            bn.reset_parameters()\n",
    "\n",
    "    def forward(self, x, adj_t):\n",
    "        for i, conv in enumerate(self.convs[:-1]):\n",
    "            x = conv(x, adj_t)\n",
    "            x = self.bns[i](x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "        x = self.convs[-1](x, adj_t)\n",
    "        return x.log_softmax(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-113-23127eac7f65>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model = GCN(data.num_features, args.hidden_channels,\n\u001b[0m\u001b[1;32m      2\u001b[0m                     \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                     args.dropout).to(device)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "model = GCN(data.num_features, args.hidden_channels,\n",
    "                    dataset.num_classes, args.num_layers,\n",
    "                    args.dropout).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ]
}